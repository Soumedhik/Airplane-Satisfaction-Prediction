# Classification Models Implementation

## Overview
This repository contains the implementation of various classification models for binary classification. The models include Artificial Neural Network (ANN), Decision Tree Classifier, AdaBoost, and Extreme Gradient Boosting (XGBoost). The code is designed to solve a binary classification problem, and a comparative analysis of the models' performances is presented.

## File Structure
- **/data:** Contains the dataset files (train.csv, test.csv).
- **/results:** Output folder for model results and visualizations.
- **/src:**
  - **ann_model.ipynb:** Jupyter Notebook for ANN implementation.
  - **decision_tree_model.ipynb:** Jupyter Notebook for Decision Tree Classifier implementation.
  - **adaboost_model.ipynb:** Jupyter Notebook for AdaBoost implementation.
  - **xgboost_model.ipynb:** Jupyter Notebook for XGBoost implementation.

## Usage
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/classification-models.git
   cd classification-models
Install dependencies:

bash
Copy code
pip install -r requirements.txt
Run the Jupyter Notebooks:

Open and run each notebook (ann_model.ipynb, decision_tree_model.ipynb, adaboost_model.ipynb, xgboost_model.ipynb) to reproduce the results.
View Results:

Check the /results folder for output files and visualizations.
Results
Here are the accuracies achieved by different models:

Model	Accuracy
ANN	0.9528
Decision Tree	0.9531
AdaBoost	0.9263
XGBoost	0.9597
Conclusion
In this analysis, XGBoost performed the best with an accuracy of 0.9597.

Contact
For any questions or feedback, feel free to reach out to:

Soumedhik Bharati
